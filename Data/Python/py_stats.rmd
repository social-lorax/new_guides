---
output: 
  html_document:
    highlight: tango
    toc: true
    toc_float: true
    toc_depth: 4
    number_sections: false
    df_print: kable
knit: furmanr::knit_output_dir("C:/Users/brenner/Documents/GitHub/guides")
---

```{r include=FALSE}
library(kableExtra)
library(tidyverse)
library(gapminder)


knitr::opts_chunk$set(comment = NA, message = FALSE, warning = FALSE)

output <- function(data) {
  knitr::kable(data) %>% 
    kable_styling(full_width = F)
}

library(reticulate)
use_python("Anaconda3/Scripts/conda.exe")
use_condaenv("C:/Users/brenner/AppData/Local/r-miniconda/envs/guides")
```

\newcommand\first[1]{\color{darkblue}{\textbf{#1}}}
\newcommand\second[1]{\color{dodgerblue}{\textbf{#1}}}
\newcommand\third[1]{\color{skyblue}{\textrm{#1}}}

[Return to Data Page](data_home.html)

![](https://github.com/social-lorax/new_guides/blob/main/Images/Stats/stats_header.jpg?raw=true)

<img src="https://github.com/social-lorax/new_guides/blob/main/Images/Underlines/stats.gif?raw=true" height="100" width ="1000">

```{python}
import numpy as np
from numpy import random
import pandas as pd

from scipy import stats
from scipy.stats import norm #normal
from scipy.stats import genextreme as gev #generalized extreme value
from scipy.stats import pareto #pareto

import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')
```

<img src="https://github.com/social-lorax/new_guides/blob/main/Images/Underlines/stats.gif?raw=true" height="100" width ="1000">

# $\first{Probability}$

****

### $\second{Binary}$

```{python}
np.random.seed(613)
pass_fail = stats.bernoulli.rvs(p = 0.7, size = 100)

pass_fail
```

<br>

#### $\third{- Probabilities}$

Probability of Success = p

```{python}
round(sum(pass_fail) / len(pass_fail), 2)
```

Probabilty of Failure = q = 1 - p

```{python}
round(1 - (sum(pass_fail) / len(pass_fail)), 2)
```

<br> 

#### $\third{- Distribution}$

```{python}
pass_fail = np.array(pass_fail, dtype=str)

sns.histplot(pass_fail,
             color = 'darkblue')
plt.show()
```

****

### $\second{Discrete}$

```{python}
grade = np.random.choice(np.array(['A','B','C','F']), 100, p=[0.15,0.55,0.2,0.1])

grade
```

<br>

#### $\third{- Probabilities}$

```{python}
P = {}

P["A"] = sum(grade == "A") / len(grade)
P["B"] = sum(grade == "B") / len(grade)
P["C"] = sum(grade == "C") / len(grade)
P["F"] = sum(grade == "F") / len(grade)

P
```

<br> 

#### $\third{- Distribution}$

```{python}
grade.sort()

sns.histplot(grade,
             color = 'darkblue')
plt.show()
```

****

### $\second{Continuous}$

```{python}
score = np.random.normal(loc=60, scale=15, size=100)

score
```

<br> 

#### $\third{- Probabilities}$

The probability of a specific outcome are extremely low because there are an infinite number of possible outcomes:

```{python}
sum(score == 80.0) / len(score)
```

Instead, look at higher, lower, or a range:

```{python}
sum((score > 75) & (score < 85)) / len(score)
```

<br> 

#### $\third{- Distribution}$

```{python}
sns.histplot(score, 
             kde = True, 
             bins = 20, 
             color = 'darkblue')
plt.show()
```

<img src="https://github.com/social-lorax/new_guides/blob/main/Images/Underlines/stats.gif?raw=true" height="100" width ="1000">

# $\first{Probability Distributions}$

****

### $\second{Types}$

#### $\third{Binomial}$

*A single binary event is a Bernoulli distribution, a collection of Bernoulli events is a binomial distribution.*

* The experiment consists of a fixed number of trials (n)
* Each trial has only two possible outcomes: success and failure
* The probability of success (p) and the probability of failure (q) are constant throughout the experiment
* Each trial is independent of every other trial

If true, then for n trials and r successes:

* $P[r,n]=\frac{n!}{(n-r)!r!}*p^r*q^{n-r}$
* $\mu=n*p$
* $\sigma=\sqrt{n*p*q}$
 
```{python} 
#Eg. filliping a coin 10 times, 10000 times
trials = []

for i in range(0, 10000):
    sample = stats.bernoulli.rvs(p = 0.5, size = 10)
    trials.append(sum(sample))

print(trials[0:100])
```

```{python}
#Expected Mean = n * p = 10 * 0.5 = 5
np.mean(trials)
```

```{python}
#Expected Standard Deviation = sqrt(n * p * (1 - p)) = sqrt(10 * 0.5 * (1 - 0.5)) = 1.58
np.std(trials)
```

```{python}
sns.histplot(trials,
             color = 'darkblue',
             bins = 10)

plt.axvline(np.mean(trials), color = 'r', ls = '--', lw = 2.0)
plt.axvline(np.mean(trials) - np.std(trials), color = 'g', ls = '--', lw = 2.0)
plt.axvline(np.mean(trials) + np.std(trials), color = 'g', ls = '--', lw = 2.0)

plt.show()
```

<br>

#### $\third{Poisson}$

* The experiment consists of counting the number of occurrences over a period or space
* The mean has to be the same for each interval of measurement (e.g. each hour or mile)
* The number of occurrences during one interval is independent of all other intervals

If true, then x given λ events in the past:

* $P[x]=\frac{\lambda^x*e^{-\lambda}}{x!}$
* $\mu=\lambda$
* $\sigma=\sqrt{\lambda}$

```{python}
#Eg. 25 hurricanes in the past 22 years

lam = 25.0 / 22

distribution = stats.poisson.pmf(range(0, 11), mu = lam)
```

```{python}
sns.barplot(x = [0,1,2,3,4,5,6,7,8,9,10], 
            y = distribution,
            color = 'darkblue')

plt.axvline(lam, color = 'r', ls = '--', lw = 2.0)
plt.axvline(lam - np.sqrt(lam), color = 'g', ls = '--', lw = 2.0)
plt.axvline(lam + np.sqrt(lam), color = 'g', ls = '--', lw = 2.0)

plt.show()
```

```{python}
#Probability of only 1
stats.poisson.pmf(1, mu = lam)
```

```{python}
#Probability of less than 3
sum(stats.poisson.pmf(range(0, 3), mu = lam))
```

```{python}
#Probability of more than 2
1 - sum(stats.poisson.pmf(range(0, 2), mu = lam))
```

<br>

#### $\third{Continuous}$

* Continuous variables 

```{python}
x = np.array(range(-500,501)) * 0.01

plt.plot(x, stats.norm.pdf(x, 0, 1))
plt.title('PDF (probability density function) of a standard normal distribution')
plt.show()
```

```{python}
plt.plot(x,stats.norm.cdf(x, 0, 1))
plt.title('CDF (cumulative distribution function) of a standard normal distribution')
plt.show()
```

<br> 

**Impact of σ**

```{python}
x = np.array(range(0, 2000)) * 0.01
mu = 10

plt.title('PDF of a normal distribution')
for sigma in range(1,6):
    plt.plot(x, stats.norm.pdf(x, mu, sigma),label='sigma={0}'.format(sigma))

plt.legend()
plt.axvline(mu, color = 'r', ls = '--', lw = 2.0)
plt.ylim([0, 0.5])

plt.show()
```

```{python}
plt.title('CDF of a normal distribution')
for sigma in range(1,6):
    plt.plot(x,stats.norm.cdf(x, mu, sigma), label = 'sigma={0}'.format(sigma))

plt.legend()
plt.ylim([0, 1.1])
plt.xlim([0, 30])

plt.show()
```

<br> 

**Percentiles**

$Z=\frac{x-\mu}{\sigma}$

![](https://github.com/social-lorax/new_guides/blob/main/Images/Stats/normal_percents.png?raw=true)

<br>

**Example**

```{python}
sample = np.random.normal(loc=60, scale=15, size=1000)
sample.mean()
```

```{python}
sample.std()
```

```{python}
sns.histplot(sample, 
             bins = 20, 
             color = 'blue',
             stat='density')

sns.kdeplot(sample, 
            color = 'darkblue',
            linewidth = 4)

plt.axvline(sample.mean(), color = 'r', ls = '--', lw = 2.0)
plt.axvline(sample.mean() - sample.std(), color = 'g', ls = '--', lw = 2.0)
plt.axvline(sample.mean() + sample.std(), color = 'g', ls = '--', lw = 2.0)

plt.show()
```

```{python}
# Above Mean, Right: Probability > 80
1 - norm.cdf(80, loc = sample.mean(), scale = sample.std())
```

```{python}
# Above Mean, Left: Probability < 80
norm.cdf(80, loc = sample.mean(), scale = sample.std())
```

```{python}
# Below Mean, Left: Probability < 40
norm.cdf(40, loc = sample.mean(), scale = sample.std())
```

```{python}
# Below Mean, Right: Probability > 40
1 - norm.cdf(40, loc = sample.mean(), scale = sample.std())
```

```{python}
# Middle: Probability 40 < x < 80
norm.cdf(80, loc = sample.mean(), scale = sample.std()) - norm.cdf(40, loc = sample.mean(), scale = sample.std())
```

****

### $\second{Fitting}$

![](https://github.com/social-lorax/new_guides/blob/main/Images/Underlines/fitting_prop_dist.png?raw=true)

```{python}
def distribution_analysis(x, log_scale = False, fit_distribution = 'None', bins = 50, vis_means = True):
    #x - array of observations
    #log_scale - analyze distribution of log(x) if True
    #fit_distribution - fit the distribution ('normal', 'gev' or 'pareto') or do nothing if 'None'
    #bins - how many bins to use for binning the data
    #vis_means - show mean and std lines if True
    
    if log_scale: 
        x1 = np.log10(x) #convert data to decimal logarithms
        xlabel = 'log(values)' #reflect in x labels
    else:
        x1 = x #leave original scale 
        xlabel = 'values'    
        
    mu = x1.mean() #compute the mean
    if log_scale: #if logscale, output log mean, its original scale, and original scale mean
        print('Log mean = {:.2f}({:.2f}), mean = {:.2f}'.format(mu, 10**mu, x.mean()))
    else:
        print('Mean = {:.2f}'.format(mu)) #otherwise print mean
    
    sigma = x1.std() #compute and output standard deviation 
    print('Standard deviation = {:.2f}'.format(sigma))
        
    #visualize histogram and the interpolated line using seaborn
    sns.histplot(x1, bins = bins, color = 'darkblue', stat = 'density')
    
    sns.kdeplot(x1, color = 'darkblue', linewidth = 4)
    
    #show vertical lines for mean and std if vis_means = True
    if vis_means:
        plt.axvline(mu, color = 'r', ls = '--', lw=2.0)
        plt.axvline(mu-sigma, color = 'g', ls = '--', lw = 2.0)
        plt.axvline(mu+sigma, color = 'g', ls = '--', lw = 2.0)
        
    ylim = plt.gca().get_ylim() #keep the y-range of original distribution density values 
    #(to make sure the fitted distribution would not affect it)
    
    h = np.arange(mu - 3 * sigma, mu + 3 * sigma, sigma / 100) #3-sigma visualization range for the fitted distribution
    pars = None #fitted distribution parameters
    
    #fit and visualize the theoretic distribution
    if fit_distribution == 'normal':
        pars = norm.fit(x1)
        plt.plot(h,norm.pdf(h,*pars),'r')
    elif fit_distribution == 'gev':
        pars = gev.fit(x1)
        plt.plot(h,gev.pdf(h,*pars),'r')
    elif fit_distribution == 'pareto':
        pars = pareto.fit(x1)
        plt.plot(h,pareto.pdf(h,*pars),'r')
    
    plt.xlabel(xlabel) #add x label 
    plt.ylim(ylim) #restore the y-range of original distribution density values 
    plt.show()
```

```{python}
distribution_analysis(sample)
```

```{python}
distribution_analysis(sample, fit_distribution = "normal")
```

```{python}
distribution_analysis(sample, fit_distribution = "pareto")
```

<img src="https://github.com/social-lorax/new_guides/blob/main/Images/Underlines/stats.gif?raw=true" height="100" width ="1000">

# $\first{Inferential Statistics}$

****

<img src="https://github.com/social-lorax/new_guides/blob/main/Images/Underlines/stats.gif?raw=true" height="100" width ="1000">

[Return to Data Page](data_home.html)
