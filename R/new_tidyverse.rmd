---
output: 
  html_document:
    highlight: tango
    toc: true
    toc_float: true
    toc_depth: 4
    number_sections: false
    df_print: kable
knit: furmanr::knit_output_dir("C:/Users/brenner/Documents/GitHub/guides")
---

\newcommand\first[1]{\color{darkblue}{\textbf{#1}}}
\newcommand\second[1]{\color{dodgerblue}{\textbf{#1}}}
\newcommand\third[1]{\color{skyblue}{\textrm{#1}}}

[Return to Main Page](new_r_index.html)

```{r include=FALSE}
library(kableExtra)

knitr::opts_chunk$set(message = FALSE, warning = FALSE)

output <- function(data) {
  knitr::kable(data) %>% 
    kable_styling(full_width = F)
  }
```

<div align="center">

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/data_science.png)

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/tidyverse.png)

<img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/R/r4ds.png" height="250"> [Link to Book](https://r4ds.had.co.nz/)

</div>

```{r}
library(tidyverse)
library(gapminder)
```

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Underlines/r_underline.png)

# $\first{Program}$

****

<img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/r_main.png" height="150">

See [Basic R](new_basic_r.html)

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Underlines/r_underline.png)

# $\first{Import}$

****

<img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/readr.png" height="150"> <img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/haven.png" height="150"> <img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/readxl.png" height="150">

[Cheatsheet for Importing Data](https://github.com/social-lorax/new_guides/blob/main/Cheatsheets/r_data_import.pdf)

Also see [tidycensus](new_tidycensus.html) and [SQL](new_sql.html)

****

### $\second{Equity Check}$

* Where does this data come from?
* Why was this data collected?
* How was this data generated?
* Is this data demographically representative?
* Who is included and who is excluded from this data?
* Whose voices, lives, and experiences are missing?
* How much can this data be disaggregated by race, gender, ethnicity, etc.?
* Are the categories mutually exclusive and fully inclusive?
* Are there “other” categories and, if so, who does that include?
* Who stands to benefit from this data?
* Who might be harmed by the collection or publication of this data?

(See more in Urban Institute’s [Do No Harm Guide](https://www.urban.org/research/publication/do-no-harm-guide-applying-equity-awareness-data-visualization/view/full_report))

****

### $\second{Tibbles}$

`as_tibble()` transforms existing data into a tibble

```{r eval = FALSE}
data %>% 
  as_tibble()
```

<br> 

`tibble()` creates a tibble from new data

```{r eval = FALSE}
tibble(x = 1:5, 
       y = 1, 
       z = x ^ 2 + y)
```

```{r echo = FALSE}
tibble(x = 1:5, 
       y = 1, 
       z = x ^ 2 + y) %>% output()
```

****

### $\second{Import Data}$

#### $\third{- Basic Files (readr)}$ 

`readr` (part of tidyverse) covers basics like csv files

* `delim = ";"` specifies the non-comma delimiter (`"\t"` is tab, `" "` is space)
* `skip = n` skips the first n lines
* `comment = "#"` drops all lines that start with (e.g.) #
* `col_names = FALSE` tells `read_csv()` not to treat the first row as headings and instead label them from `X1` to `Xn`
* `col_names = c("x", "y", "z")` renames the columns as the character vector
* `col_types = cols()` reads in the columns as the specified data type
* `na = 999` replaces dataset-specific NA values (e.g., 999) as NA

```{r eval = FALSE}
read_csv("path/to/file.csv")

read_rds("path/to/file.rds")

read_delim("path/to/file.txt", delim = ";")
```

```{r eval = FALSE}
#Best Practice
csv_data <- read_csv("path/to/file.csv",
                     col_types = cols(w = col_double(),
                                      x = col_date(format = ""),
                                      y = col_character(),
                                      z = col_logical()))
```

<br> 

#### $\third{- Stats (haven)}$ 

`haven` reads SPSS, Stata, and SAS files

```{r eval = FALSE}
library(haven)

read_sas("path/to/file.sas7bdat")

read_spss("path/to/file.spv")

read_stata("path/to/file.dta")
```

<br> 

#### $\third{- Excel (readxl)}$ 

`readxl` reads excel files (both .xls and .xlsx)

```{r eval = FALSE}
library(readxl)

read_excel("path/to/file.xlsx")
```

<br> 

#### $\third{- Databases (DBI)}$ 

`DBI`, along with a database specific backend (e.g. RMySQL, RSQLite, RPostgreSQL etc), runs SQL queries (See [SQL](new_sql.html))

```{r eval = FALSE}
library(DBI)

con <- "connection to database"

dbGetQuery(con, "
  
  SELECT * 
    FROM table
           
           ") %>% as_tibble()
```

<br> 

#### $\third{- JSON Files (jsonlite)}$

`jsonlite` reads json files

<br> 

#### $\third{- XML Files (xml2)}$

`xml2` reads XML

****

### $\second{Export}$

`write_csv()` exports a plain csv

```{r eval = FALSE}
dataset %>% write_csv("path/dataset.csv")
```

<br> 

`write_rds()` preserves formatting as an rds file

```{r eval = FALSE}
dataset %>% write_rds("path/dataset.rds")
```

****

### $\second{Initial Check}$

#### $\third{- Contents}$

`nrow()` returns the number of rows

```{r}
gapminder %>% nrow()
```
<br> 

`ncol()` returns the number of columns 

```{r}
gapminder %>% ncol()
```

<br> 

`names()` returns a list of all of the columns 

```{r}
gapminder %>% names()
```

<br> 

`distinct()` returns a list of all unique values in a specified column 

```{r}
gapminder %>% distinct(continent)
```

<br> 

#### $\third{- Summary Stats}$

`summary()` gives basic stats on numeric columns, but I prefer this custom function

```{r}
col_summaries <- function(.data){
  
  all_cols <- .data %>% names()
  
  test_col <- function(.test_col){
    test_data <- .data %>% 
      as_tibble() %>%
      rename(test = .test_col) %>% 
      mutate_if(is.logical, as.character)
    
    if(dim(test_data %>% filter(!is.na(test)))[1] == 0){
      test_data %>% 
        summarize(column = .test_col,
                  type = class(test_data$test),
                  missing = sum(is.na(test)),
                  unique_values = NA_real_,
                  example = NA_character_,
                  min = NA_real_,
                  q25 = NA_real_,
                  median = NA_real_,
                  q75 = NA_real_,
                  max = NA_real_)
    } else if(class(test_data$test) %in% c("integer", "numeric")){
      test_data %>% 
        summarize(column = .test_col,
                  type = class(test_data$test),
                  missing = sum(is.na(test)),
                  unique_values = NA_real_,
                  example = NA_character_,
                  min = min(test, na.rm = TRUE),
                  q25 = quantile(test, 0.25, na.rm = TRUE),
                  median = median(test, na.rm = TRUE),
                  q75 = quantile(test, 0.75, na.rm = TRUE),
                  max = max(test, na.rm = TRUE))
    } else {
      test_data %>% 
        summarize(column = .test_col,
                  type = class(test_data$test),
                  missing = sum(is.na(test)),
                  unique_values = n_distinct(test)) %>% 
        bind_cols(test_data %>% 
                    filter(!is.na(test)) %>% 
                    select(test) %>% 
                    head(1) %>% 
                    rename(example = test)) %>% 
        mutate(min = NA_real_,
               q25 = NA_real_,
               median = NA_real_,
               q75 = NA_real_,
               max = NA_real_ )
      } 
    }
  
  map_dfr(all_cols, test_col)
}
```

```{r eval = FALSE}
gapminder %>% col_summaries()
```

```{r echo = FALSE}
gapminder %>% col_summaries() %>% output()
```

<br> 

#### $\third{- Missing Values}$

`na = ` or `recode` sets what counts as missing 

```{r eval = FALSE}
#When importing
dataframe <- read_csv("datasource.csv", 
                      na = c("", "NA", "UNKNOWN", 999))

#When already read-in
dateframe <- dataframe %>% 
  mutate(char_col = recode(char_col, "NA" = NA_character_),
         num_col = recode(num_col, 999 = NA_integer_))
```

<br> 

`any(is.na())` checks whether there are ANY missing values

```{r}
#Overall
any(is.na(gapminder))
```

```{r}
#In a specific column
any(is.na(gapminder$lifeExp))
```

<br>

`summarize(sum(is.na()))` counts the missing values within each column

```{r eval = FALSE}
gapminder %>% 
  summarize(observations = n(),
            missing_lifeExp = sum(is.na(lifeExp)))
```

```{r echo = FALSE}
gapminder %>% 
  summarize(observations = n(),
            missing_lifeExp = sum(is.na(lifeExp))) %>% output()
```

<br> 

A list of expected values can also check completeness 

```{r eval = FALSE}
expected <- c("Africa" = 54, 
              "Americas" = 35, 
              "Asia" = 47,
              "Europe" = 43,
              "Oceania" = 14)

gapminder %>% 
  filter(year == 2007) %>% 
  group_by(continent) %>% 
  summarize(countries_represented = n()) %>% 
  mutate(countries_expected = expected[continent],
         missing_countries = countries_expected - countries_represented)
```

```{r echo = FALSE}
expected <- c("Africa" = 54, 
              "Americas" = 35, 
              "Asia" = 47,
              "Europe" = 43,
              "Oceania" = 14)

gapminder %>% 
  filter(year == 2007) %>% 
  group_by(continent) %>% 
  summarize(countries_represented = n()) %>% 
  mutate(countries_expected = expected[continent],
         missing_countries = countries_expected - countries_represented) %>% output()
```

<br> 

#### $\third{- Cross Tabs}$

`table()` creates a cross tab count

```{r}
gap_07 <- gapminder %>% 
  filter(year==2007) %>%
  mutate(country_size = case_when(pop > 3.121e+07 ~ "large",
                                  pop < 4.508e+06 ~ "small",
                                  TRUE            ~ "average"),
         country_size = factor(country_size, 
                               ordered = TRUE, 
                               levels = c("large", "average", "small")))

table(gap_07$continent, gap_07$country_size)
```

<br> 

#### $\third{- Frequency Tables}$

`prop.table()` creates a frequency table, but I prefer this custom function for formatting

```{r}
gap_07 <- gapminder %>% 
  filter(year==2007) %>%
  mutate(country_size = case_when(pop > 3.121e+07 ~ "large",
                                  pop < 4.508e+06 ~ "small",
                                  TRUE            ~ "average"),
         country_size = factor(country_size, 
                               ordered = TRUE, 
                               levels = c("large", "average", "small")))

size_table <- table(gap_07$continent, gap_07$country_size)

props <- function(col1, col2, prop_type){
  cross_tab <- table(col1, col2) 
  
  if(prop_type == "overall"){
    prop.table(cross_tab) %>% 
      as.data.frame() %>% 
      as_tibble() %>% 
      spread(col2, Freq) %>%
      janitor::adorn_totals("col") %>% 
      janitor::adorn_totals("row") %>% 
      as_tibble() %>% 
      mutate_at(vars(-col1), scales::percent, accuracy = 0.1) %>% 
      rename(` ` = col1)
  } else if(prop_type == "row"){
    prop.table(cross_tab, 2) %>% 
      as.data.frame() %>% 
      as_tibble() %>% 
      spread(col2, Freq) %>%
      janitor::adorn_totals("row") %>% 
      as_tibble() %>% 
      mutate_at(vars(-col1), scales::percent, accuracy = 0.1) %>% 
      rename(` ` = col1)
  } else{
    prop.table(cross_tab, 1) %>% 
      as.data.frame() %>% 
      as_tibble() %>% 
      spread(col2, Freq) %>%
      janitor::adorn_totals("col") %>% 
      as_tibble() %>% 
      mutate_at(vars(-col1), scales::percent, accuracy = 0.1) %>% 
      rename(` ` = col1)
  }
}
```

```{r eval = FALSE}
#Overall Proportions
props(gap_07$continent, gap_07$country_size, "overall")
```

```{r echo = FALSE}
#Overall Proportions
props(gap_07$continent, gap_07$country_size, "overall") %>% output()
```

```{r eval = FALSE}
#Column Proportions
props(gap_07$continent, gap_07$country_size, "col")
```

```{r echo = FALSE}
#Column Proportions
props(gap_07$continent, gap_07$country_size, "col") %>% output()
```

```{r eval = FALSE}
#Row Proportions
props(gap_07$continent, gap_07$country_size, "row")
```

```{r echo = FALSE}
#Row Proportions
props(gap_07$continent, gap_07$country_size, "row") %>% output()
```

<br> 

#### $\third{- Correlation Tables}$

`cor()` calculated the correlation between two variables, but this function will compare each variable to all other variables 

```{r}
library(reshape2)

get_pretty_cormap <- function (.data, .numcols) {
  cormat <- round(cor(select(.data, .numcols)), 2)
  
  reorder_cormat <- function(cormat){
    dd <- as.dist((1-cormat)/2)
    hc <- hclust(dd)
    cormat <-cormat[hc$order, hc$order]}
  cormat <- reorder_cormat(cormat)
  
  get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat)]<- NA
    return(cormat)}
  upper_tri <- get_upper_tri(cormat)
  
  melted_cormat <- melt(upper_tri, na.rm = TRUE)
  
  ggplot(melted_cormat, aes(Var2, Var1, fill = value)) +
    geom_tile(color = "white") +
    scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, limit = c(-1,1), 
                         space = "Lab", name = "Pearson\nCorrelation") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
    coord_fixed() +
    geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
    theme(axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          panel.grid.major = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          axis.ticks = element_blank(),
          legend.justification = c(1, 0),
          legend.position = c(0.6, 0.7),   
          legend.direction = "horizontal") +
    guides(fill = guide_colorbar(barwidth = 7, barheight = 1, title.position = "top", title.hjust = 0.5))}
```

```{r}
get_pretty_cormap(gapminder, c("year", "lifeExp", "pop", "gdpPercap"))
```

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Underlines/r_underline.png)

# $\first{Tidy}$

****

<img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/tibble.png" height="150"> <img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/dplyr.png" height="150"> <img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/stringr.png" height="150"> <img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/forcats.png" height="150"> <img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/lubridate.png" height="150">

[Cheatsheet for Tidying Data](https://github.com/social-lorax/new_guides/blob/main/Cheatsheets/r_data_transformation.pdf)

[Cheatsheet for Strings](https://github.com/social-lorax/new_guides/blob/main/Cheatsheets/r_strings.pdf)

[Cheatsheet for Factors](https://github.com/social-lorax/new_guides/blob/main/Cheatsheets/r_factors.pdf)

[Cheatsheet for Lubridates](https://github.com/social-lorax/new_guides/blob/main/Cheatsheets/r_lubridate.pdf)

****

### $\second{Tidy Data}$

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/R/tidy1.png)

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/R/tidy2.png)

<br> 

#### $\third{- Gather}$

```{r eval=FALSE}
dataframe %>% 
  gather(-c(cols to keep),
         key = key name, 
         value = value name, 
         factor_key = TRUE)

ratings %>% 
  gather(-Season, 
         key = Episode, 
         value = Rating, 
         factor_key = TRUE)
```

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/R/gather.png)

<br> 

#### $\third{- Spread}$

```{r eval=FALSE}
dataframe %>% 
  spread(key = col to become new cols, 
         value = col to become values under new cols, 
         fill = value to fill for missing)

roster %>% 
  spread(key = Variable, 
         value = Rating)
```

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/R/spread.png)

****

### $\second{Values}$

#### $\third{- Missing}$

`filter(!is.na())` removes entire rows with missing values in the specified column

```{r eval = FALSE}
gapminder %>% 
  filter(!is.na(lifeExp)) 
```

<br>

`replace_na()` replaces missing values

```{r eval = FALSE}
gapminder %>% 
  mutate(pop = replace_na(pop, 0))
```

<br>

#### $\third{- Duplicates}$

`distinct()` keeps unique rows and removes all others that are completely identical

```{r eval = FALSE}
data %>% 
  distinct()
```

<br> 

`distinct(col, .keep_all = TRUE)` (i.e., adding a column as an argument) just looks at the values within that column regardless of whether the other columns are the same (this will keep the first occurrence, so arrange as desired first)

```{r eval = FALSE}
#Most recent entry for each country
gapminder %>% 
  arrange(desc(year)) %>% 
  distinct(country, .keep_all = TRUE) %>% 
  head()
```

```{r echo = FALSE}
#Most recent entry for each country
gapminder %>% 
  arrange(desc(year)) %>% 
  distinct(country, .keep_all = TRUE) %>% 
  head() %>% output()
```

<br> 

#### $\third{- Outliers}$

Causes: 

* Valid measurements that happen to be extreme
* Variability in measurement
* Experimental error
* Data entry error

```{r}
#Visual Check
boxplot(gap_07$pop)
```

All of the circles are technically outliers. We know that the two extremes (China and India) are, in fact, correct. If there was a third that was that extreme, it would be an error that should be removed or replaced. Similarly, if there was a negative population, that would also be an error that should be removed or replaced.

<br> 

```{r eval = FALSE}
#3SD Check
upper_out <- mean(gap_07$pop) + (3 * sd(gap_07$pop))
lower_out <- mean(gap_07$pop) - (3 * sd(gap_07$pop))

gap_07 %>% 
  filter(pop > upper_out | pop < lower_out)
```

```{r echo = FALSE}
#3SD Check
upper_out <- mean(gap_07$pop) + (3 * sd(gap_07$pop))
lower_out <- mean(gap_07$pop) - (3 * sd(gap_07$pop))

gap_07 %>% 
  filter(pop > upper_out | pop < lower_out) %>% output()
```

****

### $\second{Selecting}$

#### $\third{- Filter (observations)}$

`filter()` selects all observations (rows) with values matching the specification(s)

|Code            |Meaning                         |
|:---------------|:-------------------------------|
|`==`            |Equal to                        |
|`!=`            |Not equal to                    |
|`>`             |Greater than                    | 
|`>=`            |Greater than or equal to        | 
|`<`             |Less than                       |
|`<=`            |Less than or equal to           |
|`%in% c()`      |Within the character vector     |
|`!(. %in% c())` |Not within the character vector |
|`is.na()`       |Is NA                           |
|`!is.na()`      |Is not NA                       |
|`between(x, y)` |Is between x and y              |
|`,` or `&`      |And                             |
|`|`             |Or                              |

```{r eval = FALSE}
gapminder %>% 
  filter(between(year, 2000, 2020),
         !(continent %in% c("Africa", "Americas", "Asia")),
         !is.na(gdpPercap)) %>% 
  filter(lifeExp > 81 |
         gdpPercap > 40000) %>% 
  head()
```

```{r echo = FALSE}
gapminder %>% 
  filter(between(year, 2000, 2020),
         !(continent %in% c("Africa", "Americas", "Asia")),
         !is.na(gdpPercap)) %>% 
  filter(lifeExp > 81 |
         gdpPercap > 40000) %>% 
  head() %>% output()
```

<br> 

#### $\third{- Select (variables)}$

`select()` selects all variables (columns) called for 

* `starts_with("abc")` selects columns that begin with “abc”
* `ends_with("xyz")` selects columns that end with “xyz”
* `contains("ijk")` selects columns that contain “ijk”
* `matches("(.)\\1")` selects columns that match a regular expression
* `everything()` selects everything else (useful for reorganizing columns)

```{r eval = FALSE}
#Just
gapminder %>% 
  select(country, year, pop) %>% 
  head()
```

```{r echo = FALSE}
#Just
gapminder %>% 
  select(country, year, pop) %>% 
  head() %>% output()
```

```{r eval = FALSE}
#Not
gapminder %>% 
  select(-c(continent, pop)) %>% 
  head()
```

```{r echo = FALSE}
#Not
gapminder %>% 
  select(-c(continent, pop)) %>% 
  head() %>% output()
```

```{r eval = FALSE}
#Range from this to that
gapminder %>% 
  select(continent:pop) %>% 
  head()
```

```{r echo = FALSE}
#Range from this to that
gapminder %>% 
  select(continent:pop) %>% 
  head() %>% output()
```

****

### $\second{Columns}$

#### $\third{- Renaming}$

`rename(new name = old name)` renames the column

```{r eval = FALSE}
gapminder %>%
  rename(population = pop) %>% 
  head()
```

```{r echo = FALSE}
gapminder %>%
  rename(population = pop) %>% 
  head() %>% output()
```

<br> 

#### $\third{- Separating}$

`separate()` splits each value within a column based on some separator 

```{r eval = FALSE}
gapminder %>% 
  separate(col = lifeExp, 
           into = c("Years", "Months"), 
           sep = "[.]") %>%
  mutate(Months = as.double(str_c("0.", Months)) * 12) %>% 
  head()
```

```{r echo = FALSE}
gapminder %>% 
  separate(col = lifeExp, 
           into = c("Years", "Months"), 
           sep = "[.]") %>%
  mutate(Months = as.double(str_c("0.", Months)) * 12) %>% 
  head() %>% output()
```

<br> 

#### $\third{- Uniting}$

`unite()` merges the values of two columns into a new column, placing some separator between the values

```{r eval = FALSE}
gapminder %>% 
  unite(col = location, 
        country, continent, 
        sep = ", ") %>%
  head()
```

```{r echo = FALSE}
gapminder %>% 
  unite(col = location, 
        country, continent, 
        sep = ", ") %>%
  head() %>% output()
```

****

### $\second{Mutating}$

`mutate()` adds columns to the existing dataframe

```{r eval = FALSE}
gapminder %>% 
  mutate(gdp = gdpPercap * as.double(pop)) %>% 
  head()
```

```{r echo = FALSE}
gapminder %>% 
  mutate(gdp = gdpPercap * as.double(pop)) %>% 
  head() %>% output()
```

<br> 

`transmute()` adds columns and then only selects the specified columns

```{r eval = FALSE}
gapminder %>% 
  transmute(country, 
            year, 
            gdp = gdpPercap * as.double(pop)) %>% 
  head()
```

```{r echo = FALSE}
gapminder %>% 
  transmute(country, 
            year, 
            gdp = gdpPercap * as.double(pop)) %>% 
  head() %>% output()
```

<br>

#### $\third{- Recasting}$

* `as.character()`
* `as.double()`
* `as.integer()`
* `as.logical()`

```{r eval = FALSE}
gapminder %>% 
  mutate(pop = as.double(pop)) %>% 
  head()
```


```{r echo = FALSE}
gapminder %>% 
  mutate(pop = as.double(pop)) %>% 
  head() %>% output()
```

<br> 

#### $\third{- Factoring}$

`factor()` recategorizes strings as categorical data; `ordered = TRUE` orders the categories by the `levels = c()` argument (otherwise it will be alphabetical)

```{r eval = FALSE}
gapminder %>% 
  mutate(country = factor(country),
         continent = factor(continent, 
                            ordered = TRUE,
                            levels = c("Asia", "Americas", "Europe", 
                                       "Africa", "Oceania"))) %>% 
  head()
```

```{r echo = FALSE}
gapminder %>% 
  mutate(country = factor(country),
         continent = factor(continent, 
                            ordered = TRUE,
                            levels = c("Asia", "Americas", "Europe", 
                                       "Africa", "Oceania"))) %>% 
  head() %>% output()
```

<br>

#### $\third{- Cases}$

`case_when()` creates a new field of categorical data (that still needs to be factored)

```{r eval = FALSE}
 gapminder %>% 
  filter(year == 2007) %>%
  mutate(country_size = case_when(pop > 3.121e+07 ~ "Large",
                                  pop < 4.508e+06 ~ "Small",
                                  TRUE            ~ "Average"),
         country_size = factor(country_size,
                               ordered = TRUE,
                               levels = c("Small", "Average", "Large"))) %>% 
  head()
```

```{r echo = FALSE}
 gapminder %>% 
  filter(year == 2007) %>%
  mutate(country_size = case_when(pop > 3.121e+07 ~ "Large",
                                  pop < 4.508e+06 ~ "Small",
                                  TRUE            ~ "Average"),
         country_size = factor(country_size,
                               ordered = TRUE,
                               levels = c("Small", "Average", "Large"))) %>% 
  head() %>% output()
```

<br>

#### $\third{- Recoding Values}$

`recode(old value = new value)` replaces all occurrences of the old value with the new value

```{r eval = FALSE}
 gapminder %>% 
  mutate(continent = recode(continent, 
                            "Asia" = "Asia & Pacific Islands",
                            "Oceania" = "Australia & New Zealand")) %>% 
  head()
```

```{r echo = FALSE}
 gapminder %>% 
  mutate(continent = recode(continent, 
                            "Asia" = "Asia & Pacific Islands",
                            "Oceania" = "Australia & New Zealand")) %>% 
  head() %>% output()
```

<br>

A lookup table recodes all values faster:

```{r eval = FALSE}
library(hflights)

hflights %>% 
  count(UniqueCarrier) %>% 
  arrange(desc(n)) %>% 
  head()
```

```{r echo = FALSE}
library(hflights)

hflights %>% 
  count(UniqueCarrier) %>% 
  arrange(desc(n)) %>% 
  head() %>% output()
```

```{r eval = FALSE}
airline_lookup_table <- c("AA" = "American",
                          "AS" = "Alaska",
                          "B6" = "JetBlue",
                          "CO" = "Continental",
                          "DL" = "Delta",
                          "OO" = "SkyWest",
                          "UA" = "United",
                          "US" = "US_Airways", 
                          "WN" = "Southwest", 
                          "EV" = "Atlantic_Southeast", 
                          "F9" = "Frontier", 
                          "FL" = "AirTran", 
                          "MQ" = "American_Eagle", 
                          "XE" = "ExpressJet", 
                          "YV" = "Mesa")

hflights %>% 
  mutate(UniqueCarrier = airline_lookup_table[UniqueCarrier]) %>%
  count(UniqueCarrier) %>% 
  arrange(desc(n)) %>% 
  head()
```

```{r echo = FALSE}
airline_lookup_table <- c("AA" = "American",
                          "AS" = "Alaska",
                          "B6" = "JetBlue",
                          "CO" = "Continental",
                          "DL" = "Delta",
                          "OO" = "SkyWest",
                          "UA" = "United",
                          "US" = "US_Airways", 
                          "WN" = "Southwest", 
                          "EV" = "Atlantic_Southeast", 
                          "F9" = "Frontier", 
                          "FL" = "AirTran", 
                          "MQ" = "American_Eagle", 
                          "XE" = "ExpressJet", 
                          "YV" = "Mesa")

hflights %>% 
  mutate(UniqueCarrier = airline_lookup_table[UniqueCarrier]) %>%
  count(UniqueCarrier) %>% 
  arrange(desc(n)) %>% 
  head() %>% output()
```

<br> 

#### $\third{- Leading/Lagging Values}$

First order with `arrange()` and `arrange(desc())`, then `lead()` and `lag()` pull the leading or lagging value

```{r eval = FALSE}
gapminder %>% 
  filter(country == "United States",
         year > 1990) %>% 
  arrange(year) %>% 
  transmute(year,
            gdpPercap,
            prior_gdpPercap = lag(gdpPercap),
            next_gdpPercap = lead(gdpPercap))
```

```{r echo = FALSE}
gapminder %>% 
  filter(country == "United States",
         year > 1990) %>% 
  arrange(year) %>% 
  transmute(year,
            gdpPercap,
            prior_gdpPercap = lag(gdpPercap),
            next_gdpPercap = lead(gdpPercap)) %>% output()
```

<br> 

#### $\third{- Rolling Analysis}$

First order with `arrange()` and `arrange(desc())`, then `cum_()` does a rolling analysis 

```{r eval = FALSE}
gapminder %>% 
  filter(country == "United States",
         year > 1990) %>% 
  arrange(year) %>% 
  transmute(year,
            gdpPercap,
            rolling_sum = cumsum(gdpPercap), 
            rolling_mean = cummean(gdpPercap), 
            min_to_date = cummin(gdpPercap),
            max_to_date = cummax(gdpPercap))
```

```{r echo = FALSE}
gapminder %>% 
  filter(country == "United States",
         year > 1990) %>% 
  arrange(year) %>% 
  transmute(year,
            gdpPercap,
            rolling_sum = cumsum(gdpPercap), 
            rolling_mean = cummean(gdpPercap), 
            min_to_date = cummin(gdpPercap),
            max_to_date = cummax(gdpPercap)) %>% 
  output()
```

<br>

#### $\third{- Whole Column Analysis}$

Calling a column by name analyzes the whole column

```{r eval = FALSE}
gapminder %>% 
  filter(year == 2007) %>% 
  transmute(country,
            continent,
            lifeExp,
            world_lifeExp = mean(lifeExp, na.rm = TRUE),
            above_world_lifeExp = lifeExp > world_lifeExp,
            pop) %>% 
  arrange(desc(pop)) %>% 
  head()
```

```{r echo = FALSE}
gapminder %>% 
  filter(year == 2007) %>% 
  transmute(country,
            continent,
            lifeExp,
            world_lifeExp = mean(lifeExp, na.rm = TRUE),
            above_world_lifeExp = lifeExp > world_lifeExp,
            pop) %>% 
  arrange(desc(pop)) %>% 
  head() %>% output()
```

<br>

#### $\third{- Rankings}$

* `ntile()` categorizes the data into n even groups
* `rank()` ranks the column

```{r eval = FALSE}
gapminder %>% 
  filter(year == 2007) %>% 
  transmute(country,
            continent,
            lifeExp,
            lifeExpQuantile = ntile(desc(lifeExp), 4),
            lifeExpRank = rank(desc(lifeExp)),
            pop) %>% 
  arrange(desc(pop)) %>% 
  head()
```

```{r echo = FALSE}
gapminder %>% 
  filter(year == 2007) %>% 
  transmute(country,
            continent,
            lifeExp,
            lifeExpQuantile = ntile(desc(lifeExp), 4),
            lifeExpRank = rank(desc(lifeExp)),
            pop) %>% 
  arrange(desc(pop)) %>% 
  head() %>% output()
```


<br>

#### $\third{- Totals}$

The `janitor` package can `adorn_totals()`

```{r eval = FALSE}
#Row total
gapminder %>% 
  filter(continent == "Oceania",
         year > 1990) %>% 
  select(country, year, pop) %>% 
  spread(year, pop) %>% 
  janitor::adorn_totals("col") %>% 
  as_tibble()
```

```{r echo = FALSE}
#Row total
gapminder %>% 
  filter(continent == "Oceania",
         year > 1990) %>% 
  select(country, year, pop) %>% 
  spread(year, pop) %>% 
  janitor::adorn_totals("col") %>% 
  as_tibble() %>% output()
```

```{r eval = FALSE}
#Column total
gapminder %>% 
  filter(continent == "Oceania",
         year > 1990) %>% 
  select(country, year, pop) %>% 
  spread(year, pop) %>% 
  janitor::adorn_totals("row") %>% 
  as_tibble()
```

```{r echo = FALSE}
#Column total
gapminder %>% 
  filter(continent == "Oceania",
         year > 1990) %>% 
  select(country, year, pop) %>% 
  spread(year, pop) %>% 
  janitor::adorn_totals("row") %>% 
  as_tibble() %>% output()
```

```{r eval = FALSE}
#Both totals
gapminder %>% 
  filter(continent == "Oceania",
         year > 1990) %>% 
  select(country, year, pop) %>% 
  spread(year, pop) %>% 
  janitor::adorn_totals("row") %>%
  janitor::adorn_totals("col") %>%
  as_tibble()
```

```{r echo = FALSE}
#Both totals
gapminder %>% 
  filter(continent == "Oceania",
         year > 1990) %>% 
  select(country, year, pop) %>% 
  spread(year, pop) %>% 
  janitor::adorn_totals("row") %>%
  janitor::adorn_totals("col") %>%
  as_tibble() %>% output()
```

<br>

#### $\third{- Grouped Analysis}$

`group_by` can perform any analysis within a group instead of over the whole column

```{r eval = FALSE}
gapminder %>% 
  filter(year == 2007) %>%
  transmute(country,
            continent,
            lifeExp,
            overall_quartile = ntile(desc(lifeExp), 4)) %>% 
  group_by(continent) %>% 
  mutate(continent_quantile = ntile(desc(lifeExp), 4)) %>% 
  ungroup() %>% 
  arrange(continent) %>% 
  head()
```

```{r echo = FALSE}
gapminder %>% 
  filter(year == 2007) %>%
  transmute(country,
            continent,
            lifeExp,
            overall_quartile = ntile(desc(lifeExp), 4)) %>% 
  group_by(continent) %>% 
  mutate(continent_quantile = ntile(desc(lifeExp), 4)) %>% 
  ungroup() %>% 
  arrange(continent) %>% 
  head() %>% output()
```

<br> 

#### $\third{- Multiple Columns}$

`mutate_all`, `mutate_at`, and `mutate_if` analyze multiple columns simultaneously with the same function

```{r eval=FALSE}
#All 
gapminder %>% 
  mutate_all(as.character) %>% 
  head()
```

```{r echo=FALSE}
gapminder %>% mutate_all(as.character) %>% head() %>% output()
```

```{r eval=FALSE}
#Just
gapminder %>% 
  mutate_at(vars(lifeExp, gdpPercap), round, 1) %>% 
  head()
```

```{r echo=FALSE}
gapminder %>% mutate_at(vars(lifeExp, gdpPercap), round, 1) %>% head() %>% output()
```

```{r eval=FALSE}
#All but
gapminder %>% 
  mutate_at(vars(-country, -continent), as.double) %>% 
  head()
```

```{r echo=FALSE}
gapminder %>% mutate_at(vars(-country, -continent), as.double) %>% head() %>% output()
```

```{r eval=FALSE}
#Like
gapminder %>% 
  mutate_at(vars(matches("gdp")), round, 1) %>% 
  head()
```

```{r echo=FALSE}
gapminder %>% mutate_at(vars(matches("gdp")), round, 1) %>% head() %>% output()
```

```{r eval=FALSE}
#If
gapminder %>% 
  mutate_if(is.numeric, scales::comma, accuracy = 0.1) %>% 
  head()
```

```{r echo=FALSE}
gapminder %>% mutate_if(is.numeric, scales::comma, accuracy = 0.1) %>% head() %>% output()
```

****

### $\second{Summarizing}$

`summarize()` groups and returns a single summary statistic

```{r eval=FALSE}
gapminder %>% 
  filter(year == 2007) %>% 
  group_by(continent) %>% 
  summarize(count = n(), 
            missing = sum(is.na(lifeExp)),
            unique_countries = n_distinct(country),
            low_lifeExp = min(lifeExp, na.rm = TRUE),
            high_lifeExp = max(lifeExp, na.rm = TRUE),
            mean_lifeExp = mean(lifeExp, na.rm = TRUE),
            median_lifeEx = median(lifeExp, na.rm = TRUE),
            above_world_mean = sum(lifeExp > mean(gapminder %>% 
                                                    filter(year == 2007) %>% 
                                                    .$lifeExp,
                                                  na.rm = TRUE)),
            share_above_world_mean = above_world_mean / count) %>% 
  ungroup()
```

```{r echo=FALSE}
gapminder %>% filter(year == 2007) %>% group_by(continent) %>% summarize(count = n(), missing = sum(is.na(lifeExp)), unique_countries = n_distinct(country), low_lifeExp = min(lifeExp, na.rm = TRUE), high_lifeExp = max(lifeExp, na.rm = TRUE), mean_lifeExp = mean(lifeExp, na.rm = TRUE), median_lifeEx = median(lifeExp, na.rm = TRUE), above_world_mean = sum(lifeExp > mean(gapminder %>% filter(year == 2007) %>% .$lifeExp, na.rm = TRUE)), share_above_world_mean = above_world_mean / count) %>% ungroup() %>% output()
```

****

### $\second{Strings}$

#### $\third{- Trimming Spaces}$

`str_trim()` cuts out spaces at the beginning and end of the string

```{r}
str_trim("  this is a test     ")
```

<br> 

#### $\third{- Padding}$

`str_pad()` adds a number (`width`) of characters (`pad`) at the beginning (`left`) or end (`right`) of a string

```{r}
county_codes <- c("1", "51", "201")

str_pad(county_codes, 
        width = 3, 
        side = "left", 
        pad = "0")
```

<br>

#### $\third{- Extract Number}$

`parse_number()` drops all non-numeric characters 

```{r}
parse_number("$1,234,567")
```

<br>

#### $\third{- Replacing}$

`str_replace(string, old, new)` swaps out `old` for `new` characters

```{r}
#Replace First
str_replace("bananas","a","o")

#Replace All
str_replace_all("bananas","a","o")
```

<br> 

`str_remove(string, old)` just drops the `old` characters

```{r}
#Remove  First
str_remove("bananas","a")

#Remove All
str_remove_all("bananas","a")
```

<br>

#### $\third{- Capitalization}$

`str` has some capitalization conventions (though setting all to lower is best for matching)

```{r}
text <- "nEw YoRk CiTy"

#All Lower
str_to_lower(text)

#All Upper
str_to_upper(text)

#First Word Capitalized
str_to_sentence(text)

#All Words Capitalized
str_to_title(text)
```

****

### $\second{Dates}$

```{r}
library(lubridate)
```

<br> 

A **date-time** is a point on the timeline stored as the number of sections since `1970-01-01 00:00:00 UTC`  

```{r}
as_datetime(1511870400) 
```

<br>

A **date** is a point on the timeline stored as the number of days since `1970-01-01`  

```{r}
as_date(17498)
```

<br>

A **time** is a point on the timeline stored as the number of seconds since `00:00:00`  

```{r}
hms::as_hms(10230)
```

<br>

#### $\third{- Current}$

`now()` returns the date-time 

```{r}
now()
```

<br> 

`today()` returns the date 

```{r}
today()
```

<br>

#### $\third{- Parsing}$

The functions match the order of the components. For example, `08/07/06` could be: 

* Aug 7, 2006 
* Jul 8, 2006
* Jul 6, 2008
* Jun 7, 2008

```{r}
mdy("08/07/06")
dmy("08/07/06")
ymd("08/07/06")
ydm("08/07/06")
```

<br>

It also works for more complicated renderings like "The 4th of July, 2018"

```{r}
dmy("The 4th of July, 2018")
```

<br>

And for time

```{r}
mdy_hms("08/07/06 10:09:30")
```

<br>

For more complex strings, the format can be specified: 

* `y` = year (2021 or 21, but defaults to current century)
* `m` = numerical month (1-12 or 01-12)
* `b` = month name (January or Jan)
* `d` = day of the month (1-31 or 01-31)
* `w` = numerical day of the week (0-6 with Sunday as 0)
* `a` = day of the week name (Monday or Mon)

* `_` = split between date and time 

* `H` = 24 hour (0-24 or 00-24)
* `I` = am/pm hour (1-12 or 01-12)
* `p` = am or pm when using `I`
* `M` = minute (0-59 or 00-59)
* `s` = second (0-61 or 00-61)

```{r}
parse_date_time("Monday June 1st 2010 at 4pm", orders = "amdy_Ip")
```

<br> 

#### $\third{- Time Zones}$

`tz()` checks the timezone 

```{r}
tz(ymd_hms("2017-03-11 12:00:00"))
```

<br>

`tz = ` sets the timezone

```{r}
ymd_hms("2017-03-11 12:00:00", tz = "America/Los_Angeles")
```

<br> 

`force_tz()` changes an incorrect timezone (without changing the time value)

```{r}
force_tz(ymd_hms("2017-03-11 12:00:00"), tzone = "America/New_York")
```

<br> 

`with_tz` converts to a new timezone (thus changing the time value)

```{r}
with_tz(ymd_hms("2017-03-11 12:00:00"), tzone = "America/New_York")
```

<br> 

#### $\third{- Extracting Elements}$

* `date()` = drops the time
* `year()` = year
* `month()` = month
* `day()` = number day of the month
* `yday()` = number day of the year (1-365)
* `wday()` = day of the week
* `hour()` = hour
* `min()` = minute
* `leap_year()` = true/false for leap year
* `dst()` = true/false for daylight savings
* `quarter()` = quarter of year
* `semester()` = half of year

* `label = TRUE` for word instead of number
* `abbr = TRUE` for abbreviated word

```{r} 
str_c("Today is day ", day(today()),
      " of the month of ", month(today(), label = TRUE, abbr = FALSE),
      ", which is a ", wday(today(), label = TRUE, abbr = FALSE),
      ". It is also day ", yday(today()), 
      " of ", year(today()),
      ".") 
```

<br> 

#### $\third{- Rounding}$

`round_date()` gives the nearest `unit`

```{r}
round_date(ymd("2021-06-30"), unit = "month")
```

<br> 

`ceiling_date()` rounds up

```{r}
ceiling_date(ymd_hm("2021-06-30 12:50"), unit = "15 minutes")
```

<br>

`floor_date()` rounds down

```{r}
floor_date(ymd_hm("2021-06-30 12:50"), unit = "hour")
```

<br> 

#### $\third{- Adding Time}$

Time does not behave like general number lines. To evaluate, you must ask which is more important: the datetime in the real world or the length of time (duration)?

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/R/r_date_math.png)

* `seconds()` / `dseconds()`
* `minutes()` / `dminutes()`
* `hours()` / `dhours()`
* `days()` / `ddays()`
* `weeks()` / `dweeks()`
* `months()` / `dmonths()`
* `years()` / `dyears()`

```{r eval=FALSE}
#Normal Day
normal_day <- ymd_hm("2018-01-01 24:00", tz = "America/New_York")

period <- normal_day + hours(3)

duration <- normal_day + dhours(3)

tibble(Difference = difftime(period, duration, units = "hours"),
       Period = period,
       Duration = duration)
```

```{r echo=FALSE}
normal_day <- ymd_hm("2018-01-01 24:00", tz = "America/New_York")
period <- normal_day + hours(3)
duration <- normal_day + dhours(3)
tibble(Difference = difftime(period, duration, units = "hours"), Period = period, Duration = duration) %>% output()
```

<br> 

```{r eval=FALSE}
#Daylight Savings
daylight_savings_start <- ymd_hm("2018-03-10 24:00", tz = "America/New_York")

period <- daylight_savings_start + hours(3)

duration <- daylight_savings_start + dhours(3)

tibble(Difference = difftime(period, duration, units = "hours"),
       Period = period,
       Duration = duration)
```

```{r echo=FALSE}
enter_daylight_savings <- ymd_hm("2018-03-10 24:00", tz = "America/New_York")
period <- enter_daylight_savings + hours(3)
duration <- enter_daylight_savings + dhours(3)
tibble(Difference = difftime(period, duration, units = "hours"),
       Period = period,
       Duration = duration) %>% output()
```

<br> 

```{r eval=FALSE}
#Exit Daylight Savings
daylight_savings_end <- ymd_hm("2018-11-03 24:00", tz = "America/New_York")

period <- daylight_savings_end + hours(3)

duration <- daylight_savings_end + dhours(3)

tibble(Difference = difftime(period, duration, units = "hours"),
       Period = period,
       Duration = duration)
```

```{r echo=FALSE}
daylight_savings_end <- ymd_hm("2018-11-03 24:00", tz = "America/New_York")
period <- daylight_savings_end + hours(3)
duration <- daylight_savings_end + dhours(3)
tibble(Difference = difftime(period, duration, units = "hours"), Period = period, Duration = duration) %>% output()
```

<br> 

```{r eval=FALSE}
#Normal Year
normal_year <- ymd("2018-09-20", tz = "America/New_York")

period <- normal_year + years(1)

duration <- normal_year + years(1)

tibble(Difference = difftime(period, duration, units = "days"),
       Period = period,
       Duration = duration)
```


```{r echo=FALSE}
normal_year <- ymd("2018-09-20", tz = "America/New_York")
period <- normal_year + years(1)
duration <- normal_year + years(1)
tibble(Difference = difftime(period, duration, units = "days"), Period = period, Duration = duration) %>% output()
```

<br> 

```{r eval=FALSE}
#Leap Year
leap_year <- ymd("2019-09-20", tz = "America/New_York")

period <- leap_year + years(1)

duration <- leap_year + dyears(1)

tibble(Difference = difftime(period, duration, units = "days"),
       Period = period,
       Duration = duration)
```

```{r echo=FALSE}
leap_year <- ymd("2019-09-20", tz = "America/New_York")
period <- leap_year + years(1)
duration <- leap_year + dyears(1)
tibble(Difference = difftime(period, duration, units = "days"), Period = period, Duration = duration) %>% output()
```

<br>

For months, imaginary dates (e.g. Feb 31) need to be dealt with: 

```{r}
ymd("2019-1-31") + months(1)
ymd("2019-1-31") %>% add_with_rollback(months(1))
ymd("2019-1-31") %>% add_with_rollback(months(1), roll_to_first = TRUE)
ymd("2019-1-31") + dmonths(1)
```

<br> 

#### $\third{- Difference Between Times}$

`difftime()` measures the duration between two real datetimes 

* `secs`
* `mins`
* `hours`
* `days`
* `weeks`

```{r}
#Normal Day
difftime(ymd_hm("2018-01-02 03:00", tz = "America/New_York"),
         ymd_hm("2018-01-01 24:00", tz = "America/New_York"), 
         unit = "days")
```

```{r}
#Enter Daylight Savings
difftime(ymd_hm("2018-03-11 03:00", tz = "America/New_York"),
         ymd_hm("2018-03-10 24:00", tz = "America/New_York"), 
         unit = "days")
```

```{r}
#Exit Daylight Savings
difftime(ymd_hm("2018-11-04 03:00", tz = "America/New_York"),
         ymd_hm("2018-11-03 24:00", tz = "America/New_York"), 
         unit = "days")
```

<br> 

#### $\third{- Intervals}$

`interval()` creates an interval 

```{r}
ryan <- interval(ymd("1990-11-04"), today())
ryan
```

<br> 

`int_length()` measures the length

```{r}
int_length(ryan) %>% dseconds()
```

<br> 

`int_shift()` modifies the interval 

```{r}
int_shift(ryan, days(5))
```

<br> 

`%within%` determines if a date is within the interval

```{r}
the_90s <- interval(ymd("1990-01-01"), ymd("1999-12-31"))

today() %within% the_90s
```

<br> 

`int_overlaps()` determines if two intervals overlap

```{r}
the_1900s <- interval(ymd("1900-01-01"), ymd("1999-12-31"))

the_90s %within% the_1900s
the_1900s %within% the_90s
int_overlaps(the_90s, the_1900s)
```

****

### $\second{Combining Data}$

#### $\third{- Joins}$

* `inner_join()`
* `full_join()`
* `left_join()`
* `right_join()`

```{r eval=FALSE}
# Basic
joined_data <- data1 %>%
  inner_join(data2, by = "common_col")

# Multiple keys 
joined_data <- data1 %>%
  inner_join(data2, by = c("common_col1", "common_col2")

# Key with different name
joined_data <- data1 %>%
  inner_join(data2, by = c("col from df1" = "col from df2"))
```

<br> 

#### $\third{- Filter Joins}$

```{r}
sec_council <- tibble(country = c("United States", "United Kingdom", "France", 
                                  "Russia", "China"))
```

<br> 

`semi_join()` returns data from one dataset that is present in a second dataset

```{r eval=FALSE}
gapminder %>% 
  filter(year == 2007) %>% 
  semi_join(sec_council, by = "country") 
```

```{r echo=FALSE}
gapminder %>% filter(year == 2007) %>% semi_join(sec_council, by = "country") %>% output()
```

<br> 

`anti_join()` returns data from one dataset that is NOT present in a second dataset

```{r eval=FALSE}
gapminder %>% 
  filter(year == 2007) %>% 
  anti_join(sec_council, by = "country") %>% 
  head()
```

```{r echo=FALSE}
gapminder %>% filter(year == 2007) %>% anti_join(sec_council, by = "country") %>% head() %>% output()
```

<br>

#### $\third{- Binding}$

```{r}
df1 <- tibble("A" = c(1, 2, 3),
              "B" = c(6, 5, 4))

df2 <- tibble("A" = c(4, 5, 6),
              "B" = c(3, 2, 1),
              "C" = c("L", "M", "N"))

df3 <- tibble("B" = c(4, 5, 6),
              "C" = c("1", "2", "3"))
```


<br>

`bind_rows()` tacks on new rows 

```{r eval=FALSE}
df1 %>% 
  bind_rows(df2)
```

```{r echo=FALSE}
df1 %>%  bind_rows(df2) %>% output()
```

<br>

`bind_cols()` tacks on new columns 

```{r eval=FALSE}
df1 %>% 
  bind_cols(df3)
```

```{r echo=FALSE}
df1 %>% bind_cols(df3) %>% output()
```

<br> 

#### $\third{- Sets}$

```{r}
country_z <- gapminder %>% 
  filter(year == 2007,
         str_detect(str_to_lower(country), "z"))

country_w <- gapminder %>% 
  filter(year == 2007,
         str_detect(str_to_lower(country), "w"))
```

<br> 

`union()` returns all, removing duplicates 

```{r eval=FALSE}
country_z %>% 
  union(country_w) %>% 
  head()
```

```{r echo=FALSE}
country_z %>% dplyr::union(country_w) %>% head() %>% output()
```

<br> 

`intersect()` returns only observations in both 

```{r eval=FALSE}
country_z %>% 
  intersect(country_w) %>% 
  head()
```

```{r echo=FALSE}
country_z %>% dplyr::intersect(country_w) %>% head() %>% output()
```

<br> 

`setdiff()` returns only observations in the first that are not in the second

```{r eval=FALSE}
country_z %>%
  setdiff(country_w) %>% 
  head()
```

```{r echo=FALSE}
country_z %>% dplyr::setdiff(country_w) %>% head() %>% output()
```

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Underlines/r_underline.png)

# $\first{Visualize}$

****

<img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/ggplot.png" height="150">

See [ggplot](new_basic_r.html) or [Spatial R](new_basic_r.html)

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Underlines/r_underline.png)

# $\first{Model}$

****

<img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/tidymodels_main.png" height="150">

See [Statistics](new_stats_r.html) or [tidymodels](new_tidymodels.html)

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Underlines/r_underline.png)

# $\first{Communicate}$

****

<img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/rmarkdown.png" height="150"> <img src="https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Logos/shiny.png" height="150">

See [Markdown](new_markdown.html) or [Shiny](new_shiny.html)

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Underlines/r_underline.png)
