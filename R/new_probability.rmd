---
output: 
  html_document:
    highlight: tango
    toc: true
    toc_float: true
    toc_depth: 4
    number_sections: false
    df_print: kable
knit: furmanr::knit_output_dir("C:/Users/brenner/Documents/GitHub/guides")
---

\newcommand\first[1]{\color{darkblue}{\textbf{#1}}}
\newcommand\second[1]{\color{dodgerblue}{\textbf{#1}}}
\newcommand\third[1]{\color{skyblue}{\textrm{#1}}}

[Return to Main Page](new_r_index.html)

```{r include=FALSE}
library(kableExtra)
library(tidyverse)

knitr::opts_chunk$set(message = FALSE, warning = FALSE)

output <- function(data) {
  knitr::kable(data) %>% 
    kable_styling(full_width = F)
  }
```

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Underlines/r_underline.png)

# $\first{Basic Probability}$

***

### $\second{Single Event}$ 

#### $\third{- Theoretical}$

* Calculate all options 
* Assume all options are equally likely 
* Divide successes over total 

```{r}
#Coin flip: P[H]
options <- 2 #heads or tails 
success <- 1 #heads 

success/options
```

<br> 

#### $\third{- Experimental}$

* Conduct many experiments 
* Count successes 
* Divide successes over total 

```{r}
#Coin flip: P[H] 
flips <- rbinom(100000, 1, 0.5)
success <- sum(flips == 1)

success/length(flips)
```

***

### $\second{Intersection (X ∩ Y)}$ 

Joint Probability = P(A & B) = P(A ∩ B)

<br> 

#### $\third{- Theoretical (long)}$

* Calculate all options 
* Assume all options are equally likely 
* Divide successes over total 

```{r}
#Coin flipped twice : P[A=H & B=H] 
options <- 4 #HT, HH, TH, TT 
success <- 1 #HH

success/options
```

<br> 

#### $\third{- Theoretical (short)}$

* Calculate probability of A and of B
* Multiply together 

```{r}
#Coin flipped twice : P[A=H & B=H] 
options <- 2 #heads or tails 
success_a <- 1 #heads
success_b <- 1 #heads

(success_a/options) * (success_b/options)
```

<br> 

#### $\third{- Experimental}$
 
* Conduct many experiments 
* Count successes 
* Divide successes over total 

```{r}
#Coin flipped twice : P[A=H & B=H]
flip1 <- rbinom(100000, 1, 0.5)
flip2 <- rbinom(100000, 1, 0.5)
success <- sum(flip1 & flip2)

success/length(flip1)
```

***

### $\second{Union (X ∪ Y)}$ 

P(A or B) = P(A ∪ B)

<br> 

#### $\third{- Theoretical (long)}$

* Calculate all options 
* Assume all options are equally likely 
* Divide successes over total 

```{r}
#Coin flipped twice: P[A=H | B=H] 
options <- 4 #HT, HH, TH, TT 
success <- 3 #HT, HH, TH

success/options
```

<br> 

#### $\third{- Theoretical (short)}$

* Calculate probability of A and of B
* Add P(A) to P(B) and subtract P(A & B)

```{r}
#Coin flipped twice: P[A=H | B=H] 
options <- 2 #heads or tails 
success_a <- 1 #heads
success_b <- 1 #tails

probability_a <- success_a/options
probability_b <- success_b/options
probability_ab <- (success_a/options) * (success_b/options)

probability_a + probability_b - probability_ab
```

<br> 

#### $\third{- Experimental}$

* Conduct many experiments 
* Count successes 
* Divide successes over total 

```{r}
#Coin flipped twice: P[A=H | B=H] 
flip1 <- rbinom(100000, 1, 0.5)
flip2 <- rbinom(100000, 1, 0.5)
success <- sum(flip1 | flip2)

success/length(flip1)
```

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Underlines/r_underline.png)

# $\first{Binomial Distribution}$

****

The discrete probability distribution of the number of successes in a sequence of n independent experiments, each asking a yes–no question.

* Independent experiments with a Boolean-valued outcome (e.g., coin flip)
* Probability of success (e.g., heads) = `p`
* Probability of failure (e.g., tails) = `q` = 1 - `p`
* Repeated for `n` experiments 
* A single experiment (`n` = 1) is a Bernoulli trial

****

`rbinom()` simulates a Bernoulli trial, but has an interesting naming scheme:

* `n` = number of runs 
* `size` = number of experiments per run
* `p` = probability of success

```{r}
#Flipping a coin 10,000 times
rbinom(n = 10000,
       size = 1,
       p = 0.5) %>% 
  tibble() %>% 
  ggplot(aes(x = .)) + 
  geom_histogram(bins = 2, center = 0, fill = "gray40", col = "white") + 
  scale_x_continuous(breaks = c(0:10)) + 
  labs(title = "Binomial Distribution of a Coin Flip",
       x = "Number of Heads",
       y = "Number of Trials") + 
  theme_classic()
```
<br> 

```{r}
#Flipping a coin 10 times, 10,000 times
rbinom(n = 10000,
       size = 10,
       p = 0.5) %>% 
  tibble() %>% 
  ggplot(aes(x = .)) + 
  geom_histogram(bins = 11, center = 0, fill = "gray40", col = "white") + 
  scale_x_continuous(breaks = c(0:10)) + 
  labs(title = "Binomial Distribution of 10 Coin Flips",
       x = "Number of Heads",
       y = "Number of Trials") + 
  theme_classic()
```

<br> 

`dbinom()` calculates the probability of getting exactly a certain number of successes

* `x` = number of successes
* `size` = number of experiments
* `p` = probability of success

```{r}
#Probability of exactly 5 heads
dbinom(x = 5,
       size = 10,
       p = 0.5)
```

<br> 

`pbinom()` calculates the cumulative probability of getting above or below a certain number of successes

* `q` = number of successes
* `size` = number of experiments
* `p` = probability of success
* `lower.tail` = probability <= q (`TRUE`) or probability > q (`FALSE`)

```{r}
#Probability of 5 or fewer heads
pbinom(q = 5,
       size = 10,
       p = 0.5,
       lower.tail = TRUE)
```

<br> 

The expected value (`E[x]`) = `size * p`

```{r}
#Theoretical 
10 * 0.5
```

```{r}
#Experimental
rbinom(n = 10000,
       size = 10,
       p = 0.5) %>% 
  mean()
```

<br>

The variance (`Var(X)`) = `size * p * (1 - p)`

```{r}
#Theoretical 
10 * 0.5 * (1 - 0.5)
```

```{r}
#Experimental
rbinom(n = 10000,
       size = 10,
       p = 0.5) %>% 
  var()
```

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Underlines/r_underline.png)

# $\first{Poisson Distribution}$

****

### $\second{Theoretical}$

The discrete probability distribution of a series of events where the average time between events is known, but the exact timing of events is random.

* Events occur with a known constant mean rate (λ)
* Events are independent of the time since the last event
* Essentially, a special binomial distribution when `p` is small and `n` is large

****

`rpois()` simulates a Poisson distribution:

* `n` = number of observations 
* `lambda` = constant mean rate

```{r}
#Events per year with mean of 5
rpois(n = 1000,
      lambda = 5) %>% 
  tibble() %>% 
  ggplot(aes(x = .)) + 
  geom_histogram(binwidth = 1, center = 0, fill = "gray40", col = "white") + 
  labs(title = "Poisson Distribution Events Per Year",
       x = "Number of Events",
       y = "Number of Years") + 
  scale_x_continuous(breaks = c(0:14))+
  theme_classic()
```

<br> 

`dpois()` calculates the probability of getting exactly a certain number of successes

* `x` = number of successes
* `lambda` = constant mean rate

```{r}
#Probability of exactly 5 events
dpois(x = 5,
      lambda = 5)
```

<br> 

`ppois()` calculates the cumulative probability of getting above or below a certain number of successes

* `q` = number of successes
* `lambda` = constant mean rate
* `lower.tail` = probability <= q (`TRUE`) or probability > q (`FALSE`)

```{r}
#Probability of 5 or fewer events
ppois(q = 5,
       lambda = 5,
       lower.tail = TRUE)
```

****

### $\second{Impact of λ}$

```{r echo=FALSE}
lam <- function(lambda){
  
  rpois(n = 1000000, lambda = lambda) %>% 
    tibble() %>% 
    count(factor(.)) %>% 
    mutate(n = n/1000000) %>% 
    rename(x = `factor(.)`)
}

lam(1) %>% 
  rename(lambda1 = n) %>% 
  full_join(lam(2) %>% 
              rename(lambda2 = n), 
            by = "x") %>% 
  full_join(lam(3) %>% 
              rename(lambda3 = n), 
            by = "x") %>% 
  full_join(lam(4) %>% 
              rename(lambda4 = n), 
            by = "x") %>% 
  full_join(lam(5) %>% 
              rename(lambda5 = n), 
            by = "x") %>% 
  gather(-x, key = "lambda", value = "P") %>% 
  transmute(x = as.double(x),
            lambda = str_remove(lambda, "lambda"),
            P = replace_na(P, 0)) %>% 
  filter(x <= 16) %>% 
  ggplot(aes(x = x, y = P, color = lambda, group = lambda)) + 
  geom_line() + 
  scale_color_viridis_d() +
  labs(title = "PDF of Various Values of Lambda",
       x = "Number of Events",
       y = "P",
       color = "Lambda") + 
  scale_x_continuous(breaks = c(0:16))+
  theme_classic()

```

****

### $\second{Disaster Risk}$

The Poisson Distribution is useful for disaster risk analysis when dealing, for example, with 100- and 500-year floods (i.e., floods that are expected to occur once in 100 or 500 years). With the 100 year flood, the average time between events is 100 years meaning we expect 0.01 floods a year (λ). The Poisson Distribution provides an estimate of the number of floods experienced in a given year or period of years. 

The probability of x floods over 100 years with a λ of 1 (per hundred years, 0.01 per year):

$$P[x]=\frac{\lambda^x*e^{-\lambda}}{x!}$$

```{r}
#Probability of exactly 1 flood during the next 100 years
dpois(x = 1,
      lambda = 1)
```

```{r}
#Probability of at least 1 flood during the next 100 years
ppois(q = 0,
       lambda = 1,
       lower.tail = FALSE)
```

<br>

```{r}
#Probability of exactly 1 flood during the next year
dpois(x = 1,
      lambda = 0.01)
```

```{r}
#Probability of at least 1 flood during the next year
ppois(q = 0,
       lambda = 0.01,
       lower.tail = FALSE)
```


![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Underlines/r_underline.png)

# $\first{Normal Distribution}$

****

* Continuous variable instead of Boolean 

****

`rnorm()` simulates a normal distribution:

* `n` = number of observations 
* `mean` = mean of the population
* `sd` = standard deviation of the population

```{r}
#Grades of 10,000 students with average 3.25 and standard deviation of 0.25
rnorm(n = 10000,
      mean = 3.25,
      sd = 0.25) %>% 
  tibble() %>% 
  ggplot(aes(x = .)) + 
  geom_histogram(center = 0, fill = "gray40", col = "white") + 
  labs(title = "Normal Distribution of GPA",
       x = "GPA",
       y = "Number of Students") + 
  theme_classic()
```

`pnorm()` calculates the cumulative probability of getting above or below a certain value

* `q` = value
* `mean` = mean of the population
* `sd` = standard deviation of the population
* `lower.tail` = probability <= q (`TRUE`) or probability > q (`FALSE`)

```{r}
#Probability of GPA over 3.5
pnorm(q = 3.5,
      mean = 3.25,
      sd = 0.25,
      lower.tail = FALSE)
```

![](https://raw.githubusercontent.com/social-lorax/new_guides/main/Images/Underlines/r_underline.png)
